01-23 13:25 INFO     cuda:0
01-23 13:25 INFO     Partitioning data
01-23 13:25 INFO     Data statistics: {0: {np.int64(0): np.int64(3), np.int64(1): np.int64(7), np.int64(2): np.int64(143), np.int64(3): np.int64(112), np.int64(4): np.int64(4), np.int64(5): np.int64(23), np.int64(6): np.int64(12), np.int64(7): np.int64(55), np.int64(8): np.int64(62), np.int64(9): np.int64(389)}, 1: {np.int64(0): np.int64(131), np.int64(1): np.int64(86), np.int64(2): np.int64(125), np.int64(4): np.int64(84), np.int64(5): np.int64(212), np.int64(6): np.int64(43), np.int64(7): np.int64(429)}, 2: {np.int64(0): np.int64(188), np.int64(1): np.int64(11), np.int64(2): np.int64(122), np.int64(3): np.int64(4), np.int64(4): np.int64(119), np.int64(5): np.int64(205), np.int64(6): np.int64(150), np.int64(8): np.int64(356)}, 3: {np.int64(0): np.int64(156), np.int64(1): np.int64(152), np.int64(2): np.int64(33), np.int64(3): np.int64(104), np.int64(4): np.int64(98), np.int64(5): np.int64(79), np.int64(7): np.int64(17), np.int64(8): np.int64(64), np.int64(9): np.int64(115)}, 4: {np.int64(0): np.int64(25), np.int64(1): np.int64(227), np.int64(2): np.int64(64), np.int64(3): np.int64(307), np.int64(4): np.int64(168), np.int64(5): np.int64(29), np.int64(6): np.int64(286), np.int64(7): np.int64(1)}}
01-23 13:25 INFO     Initializing nets
01-23 13:25 INFO     in comm round:0
01-23 13:25 INFO     Training network 0. n_training: 810
01-23 13:25 INFO     Training network 0
01-23 13:25 INFO     n_training: 3
01-23 13:25 INFO     n_test: 10
01-23 13:25 INFO     Epoch: 0 Loss: 16.643905
01-23 13:25 INFO     Epoch: 1 Loss: 11.950559
01-23 13:26 INFO     Epoch: 2 Loss: 11.649687
01-23 13:26 INFO      ** Training complete **
01-23 13:26 INFO     Training network 1. n_training: 1110
01-23 13:26 INFO     Training network 1
01-23 13:26 INFO     n_training: 4
01-23 13:26 INFO     n_test: 10
01-23 13:26 INFO     Epoch: 0 Loss: 15.564710
01-23 13:26 INFO     Epoch: 1 Loss: 11.797572
01-23 13:26 INFO     Epoch: 2 Loss: 11.642802
01-23 13:26 INFO      ** Training complete **
01-23 13:26 INFO     Training network 2. n_training: 1155
01-23 13:26 INFO     Training network 2
01-23 13:26 INFO     n_training: 4
01-23 13:26 INFO     n_test: 10
01-23 13:26 INFO     Epoch: 0 Loss: 15.549659
01-23 13:27 INFO     Epoch: 1 Loss: 11.756101
01-23 13:27 INFO     Epoch: 2 Loss: 11.545672
01-23 13:27 INFO      ** Training complete **
01-23 13:27 INFO     Training network 3. n_training: 818
01-23 13:27 INFO     Training network 3
01-23 13:27 INFO     n_training: 3
01-23 13:27 INFO     n_test: 10
01-23 13:27 INFO     Epoch: 0 Loss: 16.659495
01-23 13:27 INFO     Epoch: 1 Loss: 11.950430
01-23 13:27 INFO     Epoch: 2 Loss: 11.696857
01-23 13:27 INFO      ** Training complete **
01-23 13:27 INFO     Training network 4. n_training: 1107
01-23 13:27 INFO     Training network 4
01-23 13:27 INFO     n_training: 4
01-23 13:27 INFO     n_test: 10
01-23 13:27 INFO     Epoch: 0 Loss: 15.546340
01-23 13:28 INFO     Epoch: 1 Loss: 11.772329
01-23 13:28 INFO     Epoch: 2 Loss: 11.577512
01-23 13:28 INFO      ** Training complete **
01-23 13:30 INFO     >> Global Model Test accuracy Top1: 39.880000
01-23 13:30 INFO     >> Global Model Test accuracy Top5: 87.610000
01-23 13:30 INFO     in comm round:1
01-23 13:30 INFO     Training network 0. n_training: 810
01-23 13:30 INFO     Training network 0
01-23 13:30 INFO     n_training: 3
01-23 13:30 INFO     n_test: 10
01-23 13:30 INFO     Epoch: 0 Loss: 19.867922
01-23 13:30 INFO     Epoch: 1 Loss: 16.876352
01-23 13:30 INFO     Epoch: 2 Loss: 12.927212
01-23 13:30 INFO      ** Training complete **
01-23 13:30 INFO     Training network 1. n_training: 1110
01-23 13:30 INFO     Training network 1
01-23 13:30 INFO     n_training: 4
01-23 13:30 INFO     n_test: 10
01-23 13:31 INFO     Epoch: 0 Loss: 19.553008
01-23 13:31 INFO     Epoch: 1 Loss: 14.889665
01-23 13:31 INFO     Epoch: 2 Loss: 11.553979
01-23 13:31 INFO      ** Training complete **
01-23 13:31 INFO     Training network 2. n_training: 1155
01-23 13:31 INFO     Training network 2
01-23 13:31 INFO     n_training: 4
01-23 13:31 INFO     n_test: 10
01-23 13:31 INFO     Epoch: 0 Loss: 19.528578
01-23 13:31 INFO     Epoch: 1 Loss: 14.809837
01-23 13:32 INFO     Epoch: 2 Loss: 11.517727
01-23 13:32 INFO      ** Training complete **
01-23 13:32 INFO     Training network 3. n_training: 818
01-23 13:32 INFO     Training network 3
01-23 13:32 INFO     n_training: 3
01-23 13:32 INFO     n_test: 10
01-23 13:32 INFO     Epoch: 0 Loss: 20.014214
01-23 13:32 INFO     Epoch: 1 Loss: 16.984900
01-23 13:32 INFO     Epoch: 2 Loss: 13.077043
01-23 13:32 INFO      ** Training complete **
01-23 13:32 INFO     Training network 4. n_training: 1107
01-23 13:32 INFO     Training network 4
01-23 13:32 INFO     n_training: 4
01-23 13:32 INFO     n_test: 10
01-23 13:32 INFO     Epoch: 0 Loss: 19.562227
01-23 13:32 INFO     Epoch: 1 Loss: 14.805999
01-23 13:32 INFO     Epoch: 2 Loss: 11.545731
01-23 13:32 INFO      ** Training complete **
01-23 13:35 INFO     >> Global Model Test accuracy Top1: 38.640000
01-23 13:35 INFO     >> Global Model Test accuracy Top5: 87.280000
01-23 13:35 INFO     in comm round:2
01-23 13:35 INFO     Training network 0. n_training: 810
01-23 13:35 INFO     Training network 0
01-23 13:35 INFO     n_training: 3
01-23 13:35 INFO     n_test: 10
01-23 13:35 INFO     Epoch: 0 Loss: 14.500376
01-23 13:35 INFO     Epoch: 1 Loss: 12.338258
01-23 13:35 INFO     Epoch: 2 Loss: 10.747485
01-23 13:35 INFO      ** Training complete **
01-23 13:35 INFO     Training network 1. n_training: 1110
01-23 13:35 INFO     Training network 1
01-23 13:35 INFO     n_training: 4
01-23 13:35 INFO     n_test: 10
01-23 13:35 INFO     Epoch: 0 Loss: 14.125606
01-23 13:35 INFO     Epoch: 1 Loss: 11.428790
01-23 13:36 INFO     Epoch: 2 Loss: 10.214701
01-23 13:36 INFO      ** Training complete **
01-23 13:36 INFO     Training network 2. n_training: 1155
01-23 13:36 INFO     Training network 2
01-23 13:36 INFO     n_training: 4
01-23 13:36 INFO     n_test: 10
01-23 13:36 INFO     Epoch: 0 Loss: 14.176244
01-23 13:36 INFO     Epoch: 1 Loss: 11.459184
01-23 13:36 INFO     Epoch: 2 Loss: 10.190457
01-23 13:36 INFO      ** Training complete **
01-23 13:36 INFO     Training network 3. n_training: 818
01-23 13:36 INFO     Training network 3
01-23 13:36 INFO     n_training: 3
01-23 13:36 INFO     n_test: 10
01-23 13:36 INFO     Epoch: 0 Loss: 14.437481
01-23 13:36 INFO     Epoch: 1 Loss: 12.312083
01-23 13:37 INFO     Epoch: 2 Loss: 10.799761
01-23 13:37 INFO      ** Training complete **
01-23 13:37 INFO     Training network 4. n_training: 1107
01-23 13:37 INFO     Training network 4
01-23 13:37 INFO     n_training: 4
01-23 13:37 INFO     n_test: 10
01-23 13:37 INFO     Epoch: 0 Loss: 14.132406
01-23 13:37 INFO     Epoch: 1 Loss: 11.493143
01-23 13:37 INFO     Epoch: 2 Loss: 10.238545
01-23 13:37 INFO      ** Training complete **
01-23 13:39 INFO     >> Global Model Test accuracy Top1: 40.790000
01-23 13:39 INFO     >> Global Model Test accuracy Top5: 87.380000
01-23 13:39 INFO     in comm round:3
01-23 13:39 INFO     Training network 0. n_training: 810
01-23 13:39 INFO     Training network 0
01-23 13:39 INFO     n_training: 3
01-23 13:39 INFO     n_test: 10
01-23 13:40 INFO     Epoch: 0 Loss: 11.646594
01-23 13:40 INFO     Epoch: 1 Loss: 10.610537
01-23 13:40 INFO     Epoch: 2 Loss: 9.442271
01-23 13:40 INFO      ** Training complete **
01-23 13:40 INFO     Training network 1. n_training: 1110
01-23 13:40 INFO     Training network 1
01-23 13:40 INFO     n_training: 4
01-23 13:40 INFO     n_test: 10
01-23 13:40 INFO     Epoch: 0 Loss: 11.557284
01-23 13:40 INFO     Epoch: 1 Loss: 10.026882
01-23 13:40 INFO     Epoch: 2 Loss: 8.951864
01-23 13:40 INFO      ** Training complete **
01-23 13:40 INFO     Training network 2. n_training: 1155
01-23 13:40 INFO     Training network 2
01-23 13:40 INFO     n_training: 4
01-23 13:40 INFO     n_test: 10
01-23 13:41 INFO     Epoch: 0 Loss: 11.479708
01-23 13:41 INFO     Epoch: 1 Loss: 9.890214
01-23 13:41 INFO     Epoch: 2 Loss: 8.855830
01-23 13:41 INFO      ** Training complete **
01-23 13:41 INFO     Training network 3. n_training: 818
01-23 13:41 INFO     Training network 3
01-23 13:41 INFO     n_training: 3
01-23 13:41 INFO     n_test: 10
01-23 13:41 INFO     Epoch: 0 Loss: 11.625796
01-23 13:41 INFO     Epoch: 1 Loss: 10.604814
01-23 13:41 INFO     Epoch: 2 Loss: 9.467700
01-23 13:41 INFO      ** Training complete **
01-23 13:41 INFO     Training network 4. n_training: 1107
01-23 13:41 INFO     Training network 4
01-23 13:41 INFO     n_training: 4
01-23 13:41 INFO     n_test: 10
01-23 13:41 INFO     Epoch: 0 Loss: 11.438874
01-23 13:42 INFO     Epoch: 1 Loss: 9.982287
01-23 13:42 INFO     Epoch: 2 Loss: 8.818623
01-23 13:42 INFO      ** Training complete **
01-23 13:44 INFO     >> Global Model Test accuracy Top1: 41.700000
01-23 13:44 INFO     >> Global Model Test accuracy Top5: 88.280000
01-23 13:44 INFO     in comm round:4
01-23 13:44 INFO     Training network 0. n_training: 810
01-23 13:44 INFO     Training network 0
01-23 13:44 INFO     n_training: 3
01-23 13:44 INFO     n_test: 10
01-23 13:44 INFO     Epoch: 0 Loss: 9.840409
01-23 13:44 INFO     Epoch: 1 Loss: 8.662982
01-23 13:44 INFO     Epoch: 2 Loss: 7.820730
01-23 13:44 INFO      ** Training complete **
01-23 13:44 INFO     Training network 1. n_training: 1110
01-23 13:44 INFO     Training network 1
01-23 13:44 INFO     n_training: 4
01-23 13:44 INFO     n_test: 10
01-23 13:45 INFO     Epoch: 0 Loss: 9.620964
01-23 13:45 INFO     Epoch: 1 Loss: 8.229344
01-23 13:45 INFO     Epoch: 2 Loss: 7.556624
01-23 13:45 INFO      ** Training complete **
01-23 13:45 INFO     Training network 2. n_training: 1155
01-23 13:45 INFO     Training network 2
01-23 13:45 INFO     n_training: 4
01-23 13:45 INFO     n_test: 10
01-23 13:45 INFO     Epoch: 0 Loss: 9.710730
01-23 13:45 INFO     Epoch: 1 Loss: 8.165047
01-23 13:46 INFO     Epoch: 2 Loss: 7.450772
01-23 13:46 INFO      ** Training complete **
01-23 13:46 INFO     Training network 3. n_training: 818
01-23 13:46 INFO     Training network 3
01-23 13:46 INFO     n_training: 3
01-23 13:46 INFO     n_test: 10
01-23 13:46 INFO     Epoch: 0 Loss: 9.707678
01-23 13:46 INFO     Epoch: 1 Loss: 8.717104
01-23 13:46 INFO     Epoch: 2 Loss: 7.743104
01-23 13:46 INFO      ** Training complete **
01-23 13:46 INFO     Training network 4. n_training: 1107
01-23 13:46 INFO     Training network 4
01-23 13:46 INFO     n_training: 4
01-23 13:46 INFO     n_test: 10
01-23 13:46 INFO     Epoch: 0 Loss: 9.757278
01-23 13:46 INFO     Epoch: 1 Loss: 8.238377
01-23 13:47 INFO     Epoch: 2 Loss: 7.550452
01-23 13:47 INFO      ** Training complete **
01-23 13:49 INFO     >> Global Model Test accuracy Top1: 42.010000
01-23 13:49 INFO     >> Global Model Test accuracy Top5: 89.090000
