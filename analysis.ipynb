{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to parse logs\n",
    "def parse_logs(log_file):\n",
    "    \n",
    "    # Initialize variables\n",
    "    data = []\n",
    "    current_round = None\n",
    "    current_network = None\n",
    "    last_global_top1 = None\n",
    "    last_global_top5 = None\n",
    "\n",
    "    with open(log_file, 'r') as file:\n",
    "        for line in file:\n",
    "            round_match = re.search(r\"in comm round:(\\d+)\", line)\n",
    "            network_match = re.search(r\"Training network (\\d+)\", line)\n",
    "            epoch_match = re.search(r\"Epoch: (\\d+) Loss: (-?\\d+\\.\\d+)\", line)\n",
    "            global_top1_match = re.search(r\"Global Model Test accuracy Top1: (\\d+\\.\\d+)\", line)\n",
    "            global_top5_match = re.search(r\"Global Model Test accuracy Top5: (\\d+\\.\\d+)\", line)\n",
    "\n",
    "            if round_match: current_round = int(round_match.group(1))\n",
    "            elif network_match: current_network = int(network_match.group(1))\n",
    "            elif epoch_match:\n",
    "                epoch = int(epoch_match.group(1))\n",
    "                loss = float(epoch_match.group(2))\n",
    "                data.append([current_round, current_network, epoch, loss, last_global_top1, last_global_top5])\n",
    "            elif global_top1_match: last_global_top1 = float(global_top1_match.group(1))\n",
    "            elif global_top5_match: last_global_top5 = float(global_top5_match.group(1))\n",
    "            \n",
    "            df = pd.DataFrame(data, columns=['comm_round', 'net', 'epch', 'loss', 'g_acc@1', 'g_acc@5'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract metadata from log filename\n",
    "def extract_metadata(filename):\n",
    "    match = re.match(\n",
    "        r\"(?P<dataset>[^-]+)-(?P<portion>[^-]+)-(?P<method>[^-]+)-(?P<batch_size>[^-]+)-(?P<n_parties>[^-]+)-(?P<temperature>[^-]+)-(?P<tt>[^-]+)-(?P<ts>[^-]+)-(?P<epochs>[^_]+)_log-(?P<timestamp>\\d{4}-\\d{2}-\\d{2}-\\d{2}\\d{2}-\\d{2})\",\n",
    "        filename\n",
    "    )\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from all log files in the logs folder\n",
    "log_folder = \"./logs\"\n",
    "log_files = [os.path.join(log_folder, f) for f in os.listdir(log_folder) if f.endswith(\".log\")]\n",
    "\n",
    "# Process and combine data from all log files\n",
    "dataframes = {}\n",
    "for log_file in log_files:\n",
    "  filename = os.path.basename(log_file)\n",
    "  metadata = extract_metadata(filename)\n",
    "  df = parse_logs(log_file)\n",
    "  for key, value in metadata.items():\n",
    "    df[key] = value\n",
    "  dataframes[filename] = df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "combined_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "\n",
    "# Split method into method and rel_loss\n",
    "combined_df[['method', 'rel_loss']] = combined_df['method'].str.split('_', n=1, expand=True)\n",
    "\n",
    "# Normalize losses to compare them\n",
    "combined_df['normalized_loss'] = combined_df.groupby('method')['loss'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "\n",
    "# Seaborn gridstyle setting\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses\n",
    "g = sns.relplot(\n",
    "    data=combined_df,\n",
    "    x=\"comm_round\", \n",
    "    y=\"normalized_loss\", \n",
    "    kind=\"line\",\n",
    "    hue=\"method\",\n",
    "    style=\"rel_loss\",\n",
    "    marker=\"o\",\n",
    "    col=\"dataset\",\n",
    "    height=4,               \n",
    "    aspect=1.2             \n",
    ")\n",
    "plt.subplots_adjust(top=0.85)\n",
    "\n",
    "# Set axes, titles and legend\n",
    "g.set_axis_labels(\"Communication Round\", \"Normalized Loss\")\n",
    "title_map = {\"cifar10\": \"CIFAR-10\", \"svhn\": \"SVHN\"}\n",
    "for dataset_val, ax in g.axes_dict.items():\n",
    "    ax.set_title(title_map[dataset_val])\n",
    "legend = g._legend_out\n",
    "new_labels = [\"Method\", \"Default\", \"SimSiam\", \"Variant\", \"w/o RLoss\", \"w RLoss\"]\n",
    "for text_obj, new_label in zip(g._legend.texts, new_labels):\n",
    "    text_obj.set_text(new_label)\n",
    "\n",
    "plt.savefig('./figure/loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Top-1 Accuracy\n",
    "g = sns.relplot(\n",
    "    data=combined_df,\n",
    "    x=\"comm_round\", \n",
    "    y=\"g_acc@1\", \n",
    "    kind=\"line\",\n",
    "    hue=\"method\",\n",
    "    style=\"rel_loss\",\n",
    "    marker=\"o\",\n",
    "    col=\"dataset\",\n",
    "    height=4,               \n",
    "    aspect=1.2             \n",
    ")\n",
    "plt.subplots_adjust(top=0.85)\n",
    "\n",
    "# Set axes, titles and legend\n",
    "g.set_axis_labels(\"Communication Round\", \"Top-1 Accuracy\")\n",
    "title_map = {\"cifar10\": \"CIFAR-10\", \"svhn\": \"SVHN\"}\n",
    "for dataset_val, ax in g.axes_dict.items():\n",
    "    ax.set_title(title_map[dataset_val])\n",
    "legend = g._legend_out\n",
    "new_labels = [\"Method\", \"Default\", \"SimSiam\", \"Variant\", \"w/o RLoss\", \"w RLoss\"]\n",
    "for text_obj, new_label in zip(g._legend.texts, new_labels):\n",
    "    text_obj.set_text(new_label)\n",
    "\n",
    "plt.savefig('./figure/top-1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Top-5 Accuracy\n",
    "g = sns.relplot(\n",
    "    data=combined_df,\n",
    "    x=\"comm_round\", \n",
    "    y=\"g_acc@5\", \n",
    "    kind=\"line\",\n",
    "    hue=\"method\",\n",
    "    style=\"rel_loss\",\n",
    "    marker=\"o\",\n",
    "    col=\"dataset\",\n",
    "    height=4,               \n",
    "    aspect=1.2             \n",
    ")\n",
    "plt.subplots_adjust(top=0.85)\n",
    "\n",
    "# Set axes, titles and legend\n",
    "g.set_axis_labels(\"Communication Round\", \"Top-5 Accuracy\")\n",
    "title_map = {\"cifar10\": \"CIFAR-10\", \"svhn\": \"SVHN\"}\n",
    "for dataset_val, ax in g.axes_dict.items():\n",
    "    ax.set_title(title_map[dataset_val])\n",
    "legend = g._legend_out\n",
    "new_labels = [\"Method\", \"Default\", \"SimSiam\", \"Variant\", \"w/o RLoss\", \"w RLoss\"]\n",
    "for text_obj, new_label in zip(g._legend.texts, new_labels):\n",
    "    text_obj.set_text(new_label)\n",
    "\n",
    "plt.savefig('./figure/top-5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame.\n",
    "dfcopy = combined_df.copy()\n",
    "\n",
    "# Create a display column combining the method name and relative loss flag.\n",
    "dfcopy['method'] = dfcopy.apply(\n",
    "    lambda row: f\"{row['method']} + rel_loss\" if row['rel_loss'] == \"rel_loss\" else row['method'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "def compute_metrics(sub_df):\n",
    "    \"\"\"Compute the last and best top-5 accuracy for a given subgroup.\"\"\"\n",
    "    sub_df = sub_df.sort_values(\"comm_round\")\n",
    "    last_acc = sub_df.iloc[-1][\"g_acc@5\"]\n",
    "    best_acc = sub_df[\"g_acc@5\"].max()\n",
    "    return pd.Series({\"Last Acc Top5\": last_acc, \"Best Acc Top5\": best_acc})\n",
    "\n",
    "# Group by method_display and dataset, then compute the metrics.\n",
    "agg_df = (\n",
    "    dfcopy.groupby([\"method\", \"dataset\"], group_keys=False)\n",
    "    .apply(compute_metrics, include_groups=False)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot the table so that each dataset becomes the outer column with two subcolumns.\n",
    "pivot_df = agg_df.set_index([\"method\", \"dataset\"])[[\"Last Acc Top5\", \"Best Acc Top5\"]].unstack(\"dataset\")\n",
    "pivot_df = pivot_df.swaplevel(axis=1).sort_index(axis=1, level=0).reset_index()\n",
    "\n",
    "# Print the final table without showing the DataFrame index.\n",
    "print(pivot_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = pivot_df.to_latex(index=False, multirow=True)\n",
    "print(latex_table)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
